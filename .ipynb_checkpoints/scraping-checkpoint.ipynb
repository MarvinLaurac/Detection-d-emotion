{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le bouton d'acceptation des cookies n'a pas été trouvé ou une erreur est survenue: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.86)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF724896CB5+28821]\n",
      "\t(No symbol) [0x00007FF724803840]\n",
      "\t(No symbol) [0x00007FF7246A578A]\n",
      "\t(No symbol) [0x00007FF72467F4F5]\n",
      "\t(No symbol) [0x00007FF724726247]\n",
      "\t(No symbol) [0x00007FF72473ECE2]\n",
      "\t(No symbol) [0x00007FF72471F0A3]\n",
      "\t(No symbol) [0x00007FF7246EA778]\n",
      "\t(No symbol) [0x00007FF7246EB8E1]\n",
      "\tGetHandleVerifier [0x00007FF724BCFCAD+3408013]\n",
      "\tGetHandleVerifier [0x00007FF724BE741F+3504127]\n",
      "\tGetHandleVerifier [0x00007FF724BDB5FD+3455453]\n",
      "\tGetHandleVerifier [0x00007FF72495BDBB+835995]\n",
      "\t(No symbol) [0x00007FF72480EB5F]\n",
      "\t(No symbol) [0x00007FF72480A814]\n",
      "\t(No symbol) [0x00007FF72480A9AD]\n",
      "\t(No symbol) [0x00007FF7247FA199]\n",
      "\tBaseThreadInitThunk [0x00007FF865CF259D+29]\n",
      "\tRtlUserThreadStart [0x00007FF867CCAF38+40]\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.86)\nStacktrace:\n\tGetHandleVerifier [0x00007FF724896CB5+28821]\n\t(No symbol) [0x00007FF724803840]\n\t(No symbol) [0x00007FF7246A578A]\n\t(No symbol) [0x00007FF72467F4F5]\n\t(No symbol) [0x00007FF724726247]\n\t(No symbol) [0x00007FF72473ECE2]\n\t(No symbol) [0x00007FF72471F0A3]\n\t(No symbol) [0x00007FF7246EA778]\n\t(No symbol) [0x00007FF7246EB8E1]\n\tGetHandleVerifier [0x00007FF724BCFCAD+3408013]\n\tGetHandleVerifier [0x00007FF724BE741F+3504127]\n\tGetHandleVerifier [0x00007FF724BDB5FD+3455453]\n\tGetHandleVerifier [0x00007FF72495BDBB+835995]\n\t(No symbol) [0x00007FF72480EB5F]\n\t(No symbol) [0x00007FF72480A814]\n\t(No symbol) [0x00007FF72480A9AD]\n\t(No symbol) [0x00007FF7247FA199]\n\tBaseThreadInitThunk [0x00007FF865CF259D+29]\n\tRtlUserThreadStart [0x00007FF867CCAF38+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLe bouton d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macceptation des cookies n\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma pas été trouvé ou une erreur est survenue:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m---> 41\u001b[0m html \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     42\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m reviews_elements \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxt-avis text-enrichi-forum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datacamp\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:485\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    478\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET_PAGE_SOURCE)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datacamp\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:384\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    382\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    385\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datacamp\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.86)\nStacktrace:\n\tGetHandleVerifier [0x00007FF724896CB5+28821]\n\t(No symbol) [0x00007FF724803840]\n\t(No symbol) [0x00007FF7246A578A]\n\t(No symbol) [0x00007FF72467F4F5]\n\t(No symbol) [0x00007FF724726247]\n\t(No symbol) [0x00007FF72473ECE2]\n\t(No symbol) [0x00007FF72471F0A3]\n\t(No symbol) [0x00007FF7246EA778]\n\t(No symbol) [0x00007FF7246EB8E1]\n\tGetHandleVerifier [0x00007FF724BCFCAD+3408013]\n\tGetHandleVerifier [0x00007FF724BE741F+3504127]\n\tGetHandleVerifier [0x00007FF724BDB5FD+3455453]\n\tGetHandleVerifier [0x00007FF72495BDBB+835995]\n\t(No symbol) [0x00007FF72480EB5F]\n\t(No symbol) [0x00007FF72480A814]\n\t(No symbol) [0x00007FF72480A9AD]\n\t(No symbol) [0x00007FF7247FA199]\n\tBaseThreadInitThunk [0x00007FF865CF259D+29]\n\tRtlUserThreadStart [0x00007FF867CCAF38+40]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "base_url = \"https://www.jeuxvideo.com/jeux/ps5/jeu-1776970/avis/?p={page_number}\"\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "reviews = []\n",
    "notes = []\n",
    "dates = []\n",
    "accords_avis = []\n",
    "dessaccords_avis = []\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    url = base_url.format(page_number=i)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "    \n",
    "    if i == 1:\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, '.jad_cmp_paywall_button-cookies.didomi-dismiss-button'))\n",
    "            )\n",
    "            cookie_button = driver.find_element(By.CSS_SELECTOR, '.jad_cmp_paywall_button-cookies.didomi-dismiss-button')\n",
    "            cookie_button.click()\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            print(\"Le bouton d'acceptation des cookies n'a pas été trouvé ou une erreur est survenue:\", e)\n",
    "\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    \n",
    "    reviews_elements = soup.find_all(\"div\", class_=\"txt-avis text-enrichi-forum\")\n",
    "    notes_elements = soup.find_all(\"div\", class_=\"note-avis\")\n",
    "    dates_elements = soup.find_all(\"div\", class_=\"bloc-date-avis\")\n",
    "    accords_avis_elements = soup.find_all(\"span\", class_=\"plus-avis\")\n",
    "    dessaccords_avis_elements = soup.find_all(\"span\", class_=\"moins-avis\")\n",
    "\n",
    "    \n",
    "    for review in reviews_elements:\n",
    "        reviews.append(review.text.strip())\n",
    "\n",
    "    for note in notes_elements:\n",
    "        strong = note.find(\"strong\")\n",
    "        if strong:\n",
    "            notes.append(strong.text.strip())\n",
    "\n",
    "    for date in dates_elements:\n",
    "        a_tag = date.find(\"a\", class_=\"xXx lien-jv\")\n",
    "        if a_tag:\n",
    "            dates.append(a_tag.text.strip())\n",
    "\n",
    "    for accord_avis in accords_avis_elements:\n",
    "        accords_avis.append(accord_avis.text.strip())\n",
    "\n",
    "    for dessaccord_avis in dessaccords_avis_elements:\n",
    "        dessaccords_avis.append(dessaccord_avis.text.strip())\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "dict_reviews = {\n",
    "    \"review\": reviews,\n",
    "    \"notes\": notes,\n",
    "    \"dates\": dates,\n",
    "    \"accords_avis\": accords_avis,\n",
    "    \"dessaccords_avis\": dessaccords_avis\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dict_reviews)\n",
    "\n",
    "#print(df)\n",
    "\n",
    "df.head()\n",
    "df.to_csv(\"reviews_all_pages.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>notes</th>\n",
       "      <th>dates</th>\n",
       "      <th>accords_avis</th>\n",
       "      <th>dessaccords_avis</th>\n",
       "      <th>cleanned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belle blague je les eu gratuitement résultat m...</td>\n",
       "      <td>0</td>\n",
       "      <td>03/10/2023</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>belle blague gratuitement résultat mon pote de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EA qui comme d'habitude s'engraisse avec les p...</td>\n",
       "      <td>0</td>\n",
       "      <td>29/09/2023</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>comme habitude engraisse avec pigeons jeu pire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ils ont réussi à faire pire que Fifa 23 ! Mili...</td>\n",
       "      <td>0</td>\n",
       "      <td>29/09/2023</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>ont réussi faire pire fifa milieu défense oues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adepte des FIFA depuis le 96 j'ai toujours été...</td>\n",
       "      <td>5</td>\n",
       "      <td>29/09/2023</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>adepte fifa depuis toujours été convaincu prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ce n'est pas du football les joueurs glissent ...</td>\n",
       "      <td>0</td>\n",
       "      <td>30/09/2023</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>football joueurs glissent partout aucun équili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  notes       dates  \\\n",
       "0  Belle blague je les eu gratuitement résultat m...      0  03/10/2023   \n",
       "1  EA qui comme d'habitude s'engraisse avec les p...      0  29/09/2023   \n",
       "4  Ils ont réussi à faire pire que Fifa 23 ! Mili...      0  29/09/2023   \n",
       "5  Adepte des FIFA depuis le 96 j'ai toujours été...      5  29/09/2023   \n",
       "6  Ce n'est pas du football les joueurs glissent ...      0  30/09/2023   \n",
       "\n",
       "   accords_avis  dessaccords_avis  \\\n",
       "0            21                 0   \n",
       "1            17                 0   \n",
       "4            15                 0   \n",
       "5            34                 3   \n",
       "6            14                 0   \n",
       "\n",
       "                                     cleanned_review  \n",
       "0  belle blague gratuitement résultat mon pote de...  \n",
       "1  comme habitude engraisse avec pigeons jeu pire...  \n",
       "4  ont réussi faire pire fifa milieu défense oues...  \n",
       "5  adepte fifa depuis toujours été convaincu prop...  \n",
       "6  football joueurs glissent partout aucun équili...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('reviews_all_pages.csv')\n",
    "df = df.drop_duplicates(subset='review')\n",
    "\n",
    "def nettoyer_texte_complet(texte):\n",
    "    texte = str(texte).lower()\n",
    "    texte = re.sub(r'[^\\w\\s]', ' ', texte)  # Supprimer la ponctuation\n",
    "    texte = re.sub(r'\\d+', '', texte)  # Supprimer les chiffres\n",
    "    texte = re.sub(r'\\s+', ' ', texte)  # Supprimer les espaces multiples\n",
    "    texte = texte.strip()\n",
    "    \n",
    "    mots = texte.split()\n",
    "    \n",
    "    # Filtrer les mots de deux lettres\n",
    "    mots_filtres = [mot for mot in mots if len(mot) > 2]\n",
    "    \n",
    "    texte = ' '.join(mots_filtres)\n",
    "    return texte\n",
    "\n",
    "def convertir_date(date_str):\n",
    "    date_str = date_str.replace('Posté le', '')\n",
    "\n",
    "    # Extraire la partie de la date avant \"à\"\n",
    "    date_part = date_str.split(' à ')[0]\n",
    "    date_part = date_part.replace('.', '').strip()\n",
    "    # Dictionnaire des mois en français\n",
    "    mois_fr = {\n",
    "        'janv': '01', 'févr': '02', 'mars': '03', 'avr': '04',\n",
    "        'mai': '05', 'juin': '06', 'juil': '07', 'août': '08',\n",
    "        'sept': '09', 'oct': '10', 'nov': '11', 'déc': '12'\n",
    "    }\n",
    "    try:\n",
    "        parts = date_part.split(' ')\n",
    "        if len(parts) == 2:  \n",
    "            jour, mois = parts\n",
    "            annee = \"2024\"  \n",
    "        else:  \n",
    "            jour, mois, annee = parts\n",
    "        mois_num = mois_fr[mois.lower()]\n",
    "        return f\"{jour.zfill(2)}/{mois_num}/{annee}\"\n",
    "    except Exception as e:\n",
    "        return date_str\n",
    " \n",
    " \n",
    "# Liste des mots à exclure, incluant les mots de deux lettres\n",
    "stop_words = set(['et', 'le', 'la', 'un', 'une', 'de', 'à', 'les', 'des', 'pour', 'dans', 'ce', 'en', 'on', 'il', 'je', 'ils', 'est', 'que', 'pas', 'qui',\n",
    "                 'mais', 'sur', 'vous', 'même', 'avoir', 'par', 'tout', 'cette', 'plus', 'est', 'sont', 'quoi', 'donc' ])\n",
    "\n",
    "# donc nous suis son tout tous sans avait cet une  des pas que qui mon deja quelque leur vais quand peut peux devient ils elles vont tennis cette ce ans parce alors\n",
    "\n",
    " \n",
    " \n",
    "df['review'] = df['review'].str.replace(',','')\n",
    "df['cleanned_review'] = df['review']\n",
    "df['cleanned_review'] = df['cleanned_review'].apply(nettoyer_texte_complet)\n",
    "df['cleanned_review'] = df['cleanned_review'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "\n",
    "df['dates'] = df['dates'].apply(convertir_date)\n",
    "\n",
    "# Enregistrer les données nettoyées dans un nouveau fichier\n",
    "df.to_csv('nettoyer.csv', index=False)\n",
    "# Afficher les premières lignes pour vérifier\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                review classification\n",
      "0    Belle blague je les eu gratuitement résultat m...          anger\n",
      "1    EA qui comme d'habitude s'engraisse avec les p...            sad\n",
      "2    Ils ont réussi à faire pire que Fifa 23 ! Mili...            sad\n",
      "3    Adepte des FIFA depuis le 96 j'ai toujours été...            sad\n",
      "4    Ce n'est pas du football les joueurs glissent ...          anger\n",
      "..                                                 ...            ...\n",
      "129  5 pour les pelouses et c'est tout........ .......        neutral\n",
      "130  Jeux vraiment horrible script sur script passe...            sad\n",
      "131  Avant de l’acheter je trouvais la note des jou...          anger\n",
      "132  Le gameplay est à chieUne défense de mortLes f...            sad\n",
      "133  Ceux qui mettent des 0 partout et qui viennent...            joy\n",
      "\n",
      "[134 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import pandas as pd \n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"astrosbd/french_emotion_camembert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"astrosbd/french_emotion_camembert\")\n",
    "\n",
    "# Load the model into a classification pipeline\n",
    "classification_pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Liste des revues (exemple)\n",
    "df = pd.read_csv('nettoyer.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text[:510]  \n",
    "\n",
    "df['cleanned_review'] = df['cleanned_review'].apply(preprocess_text)\n",
    "df['classification'] = df['cleanned_review'].apply(lambda x: classification_pipe(x)[0]['label']) \n",
    "\n",
    "print(df[['review', 'classification']])\n",
    "\n",
    "df.to_csv('resultats_reviews.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
