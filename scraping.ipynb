{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                review notes  \\\n",
      "0    Belle blague je les eu gratuitement résultat m...     0   \n",
      "1    EA qui comme d'habitude s'engraisse avec les p...     0   \n",
      "2    Belle blague je les eu gratuitement résultat m...     0   \n",
      "3    EA qui comme d'habitude s'engraisse avec les p...     0   \n",
      "4    Ils ont réussi à faire pire que Fifa 23 ! Mili...     0   \n",
      "..                                                 ...   ...   \n",
      "148  5 pour les pelouses et c'est tout........ .......     5   \n",
      "149  Jeux vraiment horrible script sur script passe...     0   \n",
      "150  Avant de l’acheter, je trouvais la note des jo...     2   \n",
      "151  Le gameplay est à chieUne défense de mortLes f...     1   \n",
      "152  Ceux qui mettent des 0 partout et qui viennent...    19   \n",
      "\n",
      "                              dates accords_avis dessaccords_avis  \n",
      "0     Posté le 03 oct. 2023 à 11:54           21                0  \n",
      "1    Posté le 29 sept. 2023 à 19:06           17                0  \n",
      "2     Posté le 03 oct. 2023 à 11:54           21                0  \n",
      "3    Posté le 29 sept. 2023 à 19:06           17                0  \n",
      "4    Posté le 29 sept. 2023 à 18:32           15                0  \n",
      "..                              ...          ...              ...  \n",
      "148       Posté le 30 janv. à 20:17            0                0  \n",
      "149       Posté le 27 janv. à 13:38            0                0  \n",
      "150       Posté le 27 janv. à 00:48            0                0  \n",
      "151       Posté le 24 janv. à 22:26            0                0  \n",
      "152       Posté le 24 janv. à 11:26            0                3  \n",
      "\n",
      "[153 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "base_url = \"https://www.jeuxvideo.com/jeux/ps5/jeu-1776970/avis/?p={page_number}\"\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "reviews = []\n",
    "notes = []\n",
    "dates = []\n",
    "accords_avis = []\n",
    "dessaccords_avis = []\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    url = base_url.format(page_number=i)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "\n",
    "    \n",
    "    if i == 1:\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, '.jad_cmp_paywall_button-cookies.didomi-dismiss-button'))\n",
    "            )\n",
    "            cookie_button = driver.find_element(By.CSS_SELECTOR, '.jad_cmp_paywall_button-cookies.didomi-dismiss-button')\n",
    "            cookie_button.click()\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            print(\"Le bouton d'acceptation des cookies n'a pas été trouvé ou une erreur est survenue:\", e)\n",
    "\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    \n",
    "    reviews_elements = soup.find_all(\"div\", class_=\"txt-avis text-enrichi-forum\")\n",
    "    notes_elements = soup.find_all(\"div\", class_=\"note-avis\")\n",
    "    dates_elements = soup.find_all(\"div\", class_=\"bloc-date-avis\")\n",
    "    accords_avis_elements = soup.find_all(\"span\", class_=\"plus-avis\")\n",
    "    dessaccords_avis_elements = soup.find_all(\"span\", class_=\"moins-avis\")\n",
    "\n",
    "    \n",
    "    for review in reviews_elements:\n",
    "        reviews.append(review.text.strip())\n",
    "\n",
    "    for note in notes_elements:\n",
    "        strong = note.find(\"strong\")\n",
    "        if strong:\n",
    "            notes.append(strong.text.strip())\n",
    "\n",
    "    for date in dates_elements:\n",
    "        a_tag = date.find(\"a\", class_=\"xXx lien-jv\")\n",
    "        if a_tag:\n",
    "            dates.append(a_tag.text.strip())\n",
    "\n",
    "    for accord_avis in accords_avis_elements:\n",
    "        accords_avis.append(accord_avis.text.strip())\n",
    "\n",
    "    for dessaccord_avis in dessaccords_avis_elements:\n",
    "        dessaccords_avis.append(dessaccord_avis.text.strip())\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "dict_reviews = {\n",
    "    \"review\": reviews,\n",
    "    \"notes\": notes,\n",
    "    \"dates\": dates,\n",
    "    \"accords_avis\": accords_avis,\n",
    "    \"dessaccords_avis\": dessaccords_avis\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dict_reviews)\n",
    "print(df)\n",
    "df.to_csv(\"reviews_all_pages.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>notes</th>\n",
       "      <th>dates</th>\n",
       "      <th>accords_avis</th>\n",
       "      <th>dessaccords_avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>belle blague gratuitement résultat mon pote de...</td>\n",
       "      <td>0</td>\n",
       "      <td>03/10/2023</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qui comme habitude engraisse avec pigeons mais...</td>\n",
       "      <td>0</td>\n",
       "      <td>29/09/2023</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ils ont réussi faire pire que fifa milieu défe...</td>\n",
       "      <td>0</td>\n",
       "      <td>29/09/2023</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adepte fifa depuis toujours été convaincu par ...</td>\n",
       "      <td>5</td>\n",
       "      <td>29/09/2023</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>est pas football joueurs glissent partout aucu...</td>\n",
       "      <td>0</td>\n",
       "      <td>30/09/2023</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  notes       dates  \\\n",
       "0  belle blague gratuitement résultat mon pote de...      0  03/10/2023   \n",
       "1  qui comme habitude engraisse avec pigeons mais...      0  29/09/2023   \n",
       "4  ils ont réussi faire pire que fifa milieu défe...      0  29/09/2023   \n",
       "5  adepte fifa depuis toujours été convaincu par ...      5  29/09/2023   \n",
       "6  est pas football joueurs glissent partout aucu...      0  30/09/2023   \n",
       "\n",
       "   accords_avis  dessaccords_avis  \n",
       "0            21                 0  \n",
       "1            17                 0  \n",
       "4            15                 0  \n",
       "5            34                 3  \n",
       "6            14                 0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('reviews_all_pages.csv')\n",
    "df = df.drop_duplicates(subset='review')\n",
    "\n",
    "def nettoyer_texte_complet(texte):\n",
    "    texte = str(texte).lower()\n",
    "    texte = re.sub(r'[^\\w\\s]', ' ', texte)  # Supprimer la ponctuation\n",
    "    texte = re.sub(r'\\d+', '', texte)  # Supprimer les chiffres\n",
    "    texte = re.sub(r'\\s+', ' ', texte)  # Supprimer les espaces multiples\n",
    "    texte = texte.strip()\n",
    "    \n",
    "    mots = texte.split()\n",
    "    \n",
    "    # Filtrer les mots de deux lettres\n",
    "    mots_filtres = [mot for mot in mots if len(mot) > 2]\n",
    "    \n",
    "    texte = ' '.join(mots_filtres)\n",
    "    return texte\n",
    "\n",
    "def convertir_date(date_str):\n",
    "    date_str = date_str.replace('Posté le ', '')\n",
    "    date_part = date_str.split(' à ')[0]\n",
    "    date_part = date_part.replace('.', '')\n",
    "    \n",
    "    try:\n",
    "        jour, mois, annee = date_part.split(' ')\n",
    "        mois_fr = {\n",
    "            'janv': '01', 'févr': '02', 'mars': '03', 'avr': '04',\n",
    "            'mai': '05', 'juin': '06', 'juil': '07', 'août': '08',\n",
    "            'sept': '09', 'oct': '10', 'nov': '11', 'déc': '12'\n",
    "        }\n",
    "        \n",
    "        mois_num = mois_fr[mois.lower()]\n",
    "        return f\"{jour.zfill(2)}/{mois_num}/{annee}\"\n",
    "    except Exception as e:\n",
    "        return date_str\n",
    "\n",
    "# Liste des mots à exclure, incluant les mots de deux lettres\n",
    "stop_words = set(['et', 'le', 'la', 'un', 'une', 'de', 'à', 'les', 'des', 'pour', 'dans', 'ce', 'en', 'on', 'il', 'je', 'ils']) \n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['review'] = df['review'].apply(nettoyer_texte_complet)\n",
    "df['dates'] = df['dates'].apply(convertir_date)\n",
    "\n",
    "# Enregistrer les données nettoyées dans un nouveau fichier\n",
    "df.to_csv('nettoyer.csv', index=False)\n",
    "# Afficher les premières lignes pour vérifier\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                review classification\n",
      "0    belle blague gratuitement résultat mon pote de...          anger\n",
      "1    qui comme habitude engraisse avec pigeons mais...            sad\n",
      "2    ils ont réussi faire pire que fifa milieu défe...            sad\n",
      "3    adepte fifa depuis toujours été convaincu par ...            sad\n",
      "4    est pas football joueurs glissent partout aucu...          anger\n",
      "..                                                 ...            ...\n",
      "129                                  pelouses est tout        neutral\n",
      "130  jeux vraiment horrible script sur script passe...            sad\n",
      "131  avant acheter trouvais note joueurs sévère mai...          anger\n",
      "132  gameplay est chieune défense mortles femmes pl...            sad\n",
      "133  ceux qui mettent partout qui viennent dire mer...            joy\n",
      "\n",
      "[134 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import pandas as pd \n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"astrosbd/french_emotion_camembert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"astrosbd/french_emotion_camembert\")\n",
    "\n",
    "# Load the model into a classification pipeline\n",
    "classification_pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Liste des revues (exemple)\n",
    "df = pd.read_csv('nettoyer_o.csv')\n",
    "\n",
    "\n",
    "# Traiter chaque revue avec le pipeline\n",
    "df['classification'] = df['review'].apply(lambda x: classification_pipe(x)[0]['label']) \n",
    "\n",
    "print(df[['review', 'classification']])\n",
    "\n",
    "df.to_csv('resultats_reviews.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
